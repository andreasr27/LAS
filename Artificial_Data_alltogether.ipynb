{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook we reproduce the experimental analysis on artificial data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import necessary libraries and define functions for our experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scheduling_functions import *\n",
    "from scheduling_algorithms import *\n",
    "from numpy import std\n",
    "import numpy as np\n",
    "import sys\n",
    "import copy\n",
    "from random import sample, randint, seed, random\n",
    "from math import isclose, ceil, floor, e, sqrt\n",
    "from statistics import mean\n",
    "from decimal import *\n",
    "from fractions import *\n",
    "import matplotlib.pyplot as plt\n",
    "from operator import add\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a bounded random walk:\n",
    "\n",
    "def random_walk_creation(num_jobs, step_size, random_seed, m, M):\n",
    "    seed(random_seed)\n",
    "\n",
    "    ws = [0]*num_jobs\n",
    "    ws[0] = randint(m,M)\n",
    "    steps = [randint(-step_size,step_size) for i in range(1,num_jobs)]\n",
    "    for i in range(1, num_jobs):\n",
    "        ws[i] = ws[i-1] + steps[i-1]\n",
    "        ws[i] = min(ws[i], M)\n",
    "        ws[i] = max(ws[i], m)\n",
    "    return ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a job instance given a list of weights and T\n",
    "\n",
    "def job_instance_creation(ws, D):\n",
    "    # dictionary: key --> job id\n",
    "    #            value --> (weight, release time , deadline)\n",
    "    J = {}\n",
    "    job_id = 1\n",
    "    i = 0\n",
    "    for job_weight in ws:\n",
    "        J[job_id] = (job_weight , i, i+D)\n",
    "        i+=1\n",
    "        job_id+=1\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LAS_energy_ratio(_J_true, _J_pred, epsilon, alpha, dt):\n",
    "    \n",
    "    #compute energy of LAS algorithm\n",
    "    J_true = copy.deepcopy(_J_true)\n",
    "    J_pred = copy.deepcopy(_J_pred)\n",
    "    \n",
    "    speed_sol = LAS(J_pred, J_true, epsilon, dt, alpha)\n",
    "    energy_LAS = sum([s**alpha for s in speed_sol])*dt\n",
    "    \n",
    "   \n",
    "    #compute speedlist and energu consumption of the optimal schedule of the true instance\n",
    "    J_true = copy.deepcopy(_J_true)\n",
    "    J_pred = copy.deepcopy(_J_pred)\n",
    "    optimal_alg_speed_list, _ = Optimal_Alg(J_true)\n",
    "    energy_optimal = compute_energy(optimal_alg_speed_list, alpha)\n",
    "    \n",
    "    return float(energy_LAS)/energy_optimal    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns the energy ratio AVR_energy/Optimal_energy\n",
    "\n",
    "def AVR_energy_ratio(_J, alpha):\n",
    "    \n",
    "    J = copy.deepcopy(_J)\n",
    "    #speed list of average rate\n",
    "    AVR_speed_list = Avg_rate(J)\n",
    "    #energy consumption of AVR\n",
    "    energy_AVR = compute_energy(AVR_speed_list, alpha)\n",
    "    \n",
    "    J = copy.deepcopy(_J)\n",
    "    #speed list of the optimal schedule\n",
    "    optimal_alg_speed_list, _ = Optimal_Alg(J)\n",
    "    #energy consumption of the optimal schedule\n",
    "    energy_optimal = compute_energy(optimal_alg_speed_list, alpha)  \n",
    "    \n",
    "    return float(energy_AVR)/energy_optimal    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns the energy ratio OA_energy/Optimal_energy\n",
    "\n",
    "def OA_energy_ratio(_J, alpha):\n",
    "    \n",
    "    J = copy.deepcopy(_J)\n",
    "    #speed list of Optimal Available\n",
    "    OA_speed_list = OptimalOnline(J)\n",
    "    #energy consumption of Optimal Available\n",
    "    energy_OA = sum([s**alpha for s in OA_speed_list])\n",
    "    \n",
    "    J = copy.deepcopy(_J)\n",
    "    #speed list of the optimal schedule\n",
    "    optimal_alg_speed_list, _ = Optimal_Alg(J)\n",
    "    #energy consumption of the optimal schedule\n",
    "    energy_optimal = compute_energy(optimal_alg_speed_list, alpha)    \n",
    "   \n",
    "    return float(energy_OA)/energy_optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns the energy ratio BKP_energy/Optimal_energy\n",
    "\n",
    "def BKP_energy_ratio(_J, granularity, alpha):\n",
    "    \n",
    "    J = copy.deepcopy(_J)\n",
    "    #energy consumption of the BKP algorithm\n",
    "    energy_BKP = BKP_alg(J, granularity, alpha)\n",
    "\n",
    "    J = copy.deepcopy(_J)\n",
    "    #speed list of the optimal schedule\n",
    "    optimal_alg_speed_list, _ = Optimal_Alg(J)\n",
    "    #energy consumption of the optimal schedule\n",
    "    energy_optimal = compute_energy(optimal_alg_speed_list, alpha)  \n",
    "    \n",
    "    return float(energy_BKP)/energy_optimal    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we set the parameters of the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instance length and T\n",
    "num_jobs = 200\n",
    "D = 20\n",
    "\n",
    "num_of_experiments = 20\n",
    "\n",
    "\n",
    "step_size = 5\n",
    "M = 80\n",
    "m = 20\n",
    "\n",
    "# alpha parameter of the energy consumption\n",
    "alpha = 3\n",
    "\n",
    "# time granularity for BKP algorithm\n",
    "BKP_granularity = 0.25\n",
    "\n",
    "# granularity of CONV algorithm\n",
    "dt = 0.01\n",
    "\n",
    "# robustness parameters epsilon which will be tested\n",
    "epsilons=[Fraction(1,100), Fraction(20,100), Fraction(40,100), Fraction(60,100), Fraction(80,100)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to increase reproducibility we perform experiments on the same set of (random) true instances with fixed seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_true_lst = []\n",
    "w_true_lst = []\n",
    "for j in range(0,num_of_experiments):\n",
    "     #create a random walk\n",
    "    w_true = random_walk_creation(num_jobs, step_size, random_seed=j, M= M, m= m)\n",
    "    w_true_lst.append(w_true)\n",
    "    #job instance creation\n",
    "    J_true = job_instance_creation(w_true, D)\n",
    "    \n",
    "    J_true_lst.append(J_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Online Algorithms tested\n",
    "\n",
    "(1) Average Rate Heuristic (AVR)\n",
    "\n",
    "(2) Optimal Available (OA)\n",
    "\n",
    "(3) Bansal, Kimbrel and Pruhs algorithm (BKP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVR:  1.2675809010639774\n",
      "Std  0.07104477119543437\n",
      "=====================\n",
      "BKP:  7.8803797060825955\n",
      "Std  1.2663495212504527\n",
      "=====================\n",
      "OA:  1.1985253933487527\n",
      "Std  0.07003246274593491\n",
      "=====================\n"
     ]
    }
   ],
   "source": [
    "y_AVR = []\n",
    "y_BKP = []\n",
    "y_OA = []\n",
    "dummy_y_AVR = []\n",
    "dummy_y_BKP = []\n",
    "dummy_y_OA = []\n",
    "for j in range(0,num_of_experiments):\n",
    "    J_true = J_true_lst[j]\n",
    "    \n",
    "    AVR = AVR_energy_ratio(J_true,alpha)\n",
    "    BKP = BKP_energy_ratio(J_true,BKP_granularity, alpha)\n",
    "    OA = OA_energy_ratio(J_true, alpha)\n",
    "    dummy_y_AVR.append(AVR)\n",
    "    dummy_y_BKP.append(BKP)\n",
    "    dummy_y_OA.append(OA)\n",
    "std_AVR = std(dummy_y_AVR)\n",
    "std_BKP = std(dummy_y_BKP)\n",
    "std_OA  = std(dummy_y_OA)\n",
    "y_AVR.append(mean(dummy_y_AVR))\n",
    "y_BKP.append(mean(dummy_y_BKP))\n",
    "y_OA.append(mean(dummy_y_OA))\n",
    "\n",
    "print(\"AVR: \", y_AVR[-1])\n",
    "print(\"Std \", std_AVR)\n",
    "print(\"=====================\")   \n",
    "print(\"BKP: \", y_BKP[-1])\n",
    "print(\"Std \", std_BKP)\n",
    "print(\"=====================\")\n",
    "print(\"OA: \", y_OA[-1])\n",
    "print(\"Std \", std_OA)\n",
    "print(\"=====================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worst AVR:  1.3827228085885481\n",
      "=====================\n",
      "worst BKP:  10.380889582716827\n",
      "=====================\n",
      "worst OA:  1.3613134092905024\n",
      "=====================\n"
     ]
    }
   ],
   "source": [
    "print(\"worst AVR: \", max(dummy_y_AVR))\n",
    "print(\"=====================\")   \n",
    "print(\"worst BKP: \", max(dummy_y_BKP))\n",
    "print(\"=====================\")\n",
    "print(\"worst OA: \", max(dummy_y_OA))\n",
    "print(\"=====================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Accurate predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We create the artificial predictions of our \"Accurate predictor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_pred_lst = []\n",
    "for j in range(0,num_of_experiments):\n",
    "    w_true = w_true_lst[j]\n",
    "    \n",
    "    seed(j)\n",
    "    error = [randint(-step_size, step_size) for _ in range(0,num_jobs)]\n",
    "    \n",
    "    w_pred = list(map(add, w_true, error))    \n",
    "    #jon instance creation\n",
    "    J_pred = job_instance_creation(w_pred, D)\n",
    "    \n",
    "    J_pred_lst.append(J_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We test the performance of the Learning Augmented Scheduling (LAS) algorithm when combined with an \"Accurate predictor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPSILON =  1/100\n",
      "LAS scheduling:  1.0075397494928156\n",
      "Std of LAS scheduling  0.00432815821742801\n",
      "=====================\n",
      "EPSILON =  1/5\n",
      "LAS scheduling:  1.0130706593352214\n",
      "Std of LAS scheduling  0.005007302937615069\n",
      "=====================\n",
      "EPSILON =  2/5\n",
      "LAS scheduling:  1.017974594981769\n",
      "Std of LAS scheduling  0.00578540691382172\n",
      "=====================\n",
      "EPSILON =  3/5\n",
      "LAS scheduling:  1.0222734294264288\n",
      "Std of LAS scheduling  0.0065593000867124\n",
      "=====================\n",
      "EPSILON =  4/5\n",
      "LAS scheduling:  1.0262250101527997\n",
      "Std of LAS scheduling  0.007335483925709539\n",
      "=====================\n"
     ]
    }
   ],
   "source": [
    "for epsilon in epsilons:\n",
    "    print(\"EPSILON = \", epsilon)\n",
    "    y_LAS_scheduling = []\n",
    "    \n",
    "    dummy_y_LAS_schedulling = []\n",
    "    for j in range(0,num_of_experiments):\n",
    "        J_true = J_true_lst[j]\n",
    "        w_true = w_true_lst[j]\n",
    "        J_pred = J_pred_lst[j]\n",
    "            \n",
    "        \n",
    "        LAS_scheduling = LAS_energy_ratio(J_true, J_pred, epsilon, alpha, dt)\n",
    "\n",
    "        dummy_y_LAS_schedulling.append(LAS_scheduling)\n",
    "    \n",
    "\n",
    "    \n",
    "    y_LAS_scheduling.append(mean(dummy_y_LAS_schedulling))\n",
    "    std_LAS_scheduling = std(dummy_y_LAS_schedulling)\n",
    "    \n",
    "    \n",
    "    print(\"LAS scheduling: \", y_LAS_scheduling[-1])\n",
    "    print(\"Std of LAS scheduling \", std_LAS_scheduling)\n",
    "    print(\"=====================\")     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Random predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### we create the artificial predictions of our \"Random predictor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_pred_lst = []\n",
    "for j in range(0,num_of_experiments):\n",
    "    seed(j)\n",
    "    error = [randint(-step_size, step_size) for _ in range(0,num_jobs)]\n",
    "    \n",
    "    w_pred = [randint(m,M) for _ in range(0,num_jobs)]\n",
    "    \n",
    "    \n",
    "    #jon instance creation\n",
    "    J_pred = job_instance_creation(w_pred, D)\n",
    "    \n",
    "    J_pred_lst.append(J_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We test the performance of the Learning Augmented Scheduling (LAS) algorithm when combined with a \"Random predictor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPSILON =  1/100\n",
      "LAS scheduling:  1.2394752538463858\n",
      "Std of LAS scheduling  0.17250843763873255\n",
      "=====================\n",
      "EPSILON =  1/5\n",
      "LAS scheduling:  1.2239815495837538\n",
      "Std of LAS scheduling  0.14724187216333076\n",
      "=====================\n",
      "EPSILON =  2/5\n",
      "LAS scheduling:  1.2127922268228106\n",
      "Std of LAS scheduling  0.12990693420691735\n",
      "=====================\n",
      "EPSILON =  3/5\n",
      "LAS scheduling:  1.2065392431134532\n",
      "Std of LAS scheduling  0.1197132996358433\n",
      "=====================\n",
      "EPSILON =  4/5\n",
      "LAS scheduling:  1.2033045200807153\n",
      "Std of LAS scheduling  0.11307804236368527\n",
      "=====================\n"
     ]
    }
   ],
   "source": [
    "for epsilon in epsilons:\n",
    "    print(\"EPSILON = \", epsilon)\n",
    "    y_LAS_scheduling = []\n",
    "    \n",
    "    dummy_y_LAS_schedulling = []\n",
    "    for j in range(0,num_of_experiments):\n",
    "        J_true = J_true_lst[j]\n",
    "        J_pred = J_pred_lst[j]\n",
    "            \n",
    "        \n",
    "        LAS_scheduling = LAS_energy_ratio(J_true, J_pred, epsilon, alpha, dt)\n",
    "\n",
    "        dummy_y_LAS_schedulling.append(LAS_scheduling)\n",
    "    \n",
    "    \n",
    "    y_LAS_scheduling.append(mean(dummy_y_LAS_schedulling))\n",
    "    std_LAS_scheduling = std(dummy_y_LAS_schedulling)\n",
    "    \n",
    "    \n",
    "    print(\"LAS scheduling: \", y_LAS_scheduling[-1])\n",
    "    print(\"Std of LAS scheduling \", std_LAS_scheduling)\n",
    "    print(\"=====================\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misleading predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We create the artificial predictions of our \"Misleading predictor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_pred_lst = []\n",
    "for j in range(0,num_of_experiments):\n",
    "    w_true = w_true_lst[j]\n",
    "    \n",
    "    w_pred = []\n",
    "    for i in range(0,num_jobs):\n",
    "        w_pred.append((M-w_true[i]) + m)\n",
    "    \n",
    "    \n",
    "    #jon instance creation\n",
    "    J_pred = job_instance_creation(w_pred, D)\n",
    "    \n",
    "    J_pred_lst.append(J_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We test the performance of the Learning Augmented Scheduling (LAS) algorithm when combined with a \"Misleading predictor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPSILON =  1/100\n",
      "LAS scheduling:  1.4040283929377526\n",
      "Std of LAS scheduling  0.18755807607768799\n",
      "=====================\n",
      "EPSILON =  1/5\n",
      "LAS scheduling:  1.4062699075727747\n",
      "Std of LAS scheduling  0.1857250485744134\n",
      "=====================\n",
      "EPSILON =  2/5\n",
      "LAS scheduling:  1.4069707494536996\n",
      "Std of LAS scheduling  0.1839259349874737\n",
      "=====================\n",
      "EPSILON =  3/5\n",
      "LAS scheduling:  1.406920096057823\n",
      "Std of LAS scheduling  0.18142601778836964\n",
      "=====================\n",
      "EPSILON =  4/5\n",
      "LAS scheduling:  1.4072313575386666\n",
      "Std of LAS scheduling  0.17917555303510502\n",
      "=====================\n"
     ]
    }
   ],
   "source": [
    "for epsilon in epsilons:\n",
    "    print(\"EPSILON = \", epsilon)\n",
    "    y_LAS_scheduling = []\n",
    "    \n",
    "    dummy_y_LAS_schedulling = []\n",
    "    for j in range(0,num_of_experiments):\n",
    "        J_true = J_true_lst[j]\n",
    "        J_pred = J_pred_lst[j]\n",
    "            \n",
    "        \n",
    "        LAS_scheduling = LAS_energy_ratio(J_true, J_pred, epsilon, alpha, dt)\n",
    "\n",
    "        dummy_y_LAS_schedulling.append(LAS_scheduling)\n",
    "    \n",
    "    \n",
    "    y_LAS_scheduling.append(mean(dummy_y_LAS_schedulling))\n",
    "    std_LAS_scheduling = std(dummy_y_LAS_schedulling)\n",
    "    \n",
    "    \n",
    "    print(\"LAS scheduling: \", y_LAS_scheduling[-1])\n",
    "    print(\"Std of LAS scheduling \", std_LAS_scheduling)\n",
    "    print(\"=====================\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPSILON =  1/100\n",
      "worst LAS scheduling:  1.766393940546647\n",
      "=====================\n",
      "EPSILON =  1/5\n",
      "worst LAS scheduling:  1.7694663182826558\n",
      "=====================\n",
      "EPSILON =  2/5\n",
      "worst LAS scheduling:  1.767065435654167\n",
      "=====================\n",
      "EPSILON =  3/5\n",
      "worst LAS scheduling:  1.7578459665461634\n",
      "=====================\n",
      "EPSILON =  4/5\n",
      "worst LAS scheduling:  1.750487346257285\n",
      "=====================\n"
     ]
    }
   ],
   "source": [
    "for epsilon in epsilons:\n",
    "    print(\"EPSILON = \", epsilon)\n",
    "    y_LAS_scheduling = []\n",
    "    \n",
    "    dummy_y_LAS_schedulling = []\n",
    "    for j in range(0,num_of_experiments):\n",
    "        J_true = J_true_lst[j]\n",
    "        J_pred = J_pred_lst[j]\n",
    "            \n",
    "        \n",
    "        LAS_scheduling = LAS_energy_ratio(J_true, J_pred, epsilon, alpha, dt)\n",
    "\n",
    "        dummy_y_LAS_schedulling.append(LAS_scheduling)\n",
    "    \n",
    "    \n",
    "    y_LAS_scheduling.append(max(dummy_y_LAS_schedulling))\n",
    "    \n",
    "    \n",
    "    print(\"worst LAS scheduling: \", y_LAS_scheduling[-1])\n",
    "    print(\"=====================\")     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
